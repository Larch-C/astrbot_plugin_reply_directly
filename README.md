# Reply Directly - 智能群聊增强插件 for AstrBot

[![Plugin Version](https://img.shields.io/badge/version-1.3.0-blue.svg)](https://github.com/qa296/astrbot_plugin_reply_directly)
[![For AstrBot](https://img.shields.io/badge/for-AstrBot-orange.svg)](https://github.com/AstrBotDevs/AstrBot)

让您的 AstrBot 在群聊中变得更加生动和智能！本插件赋予了机器人两种强大的能力：**沉浸式对话**和**主动插话**，使其不再是一个被动等待指令的工具，而是一个能主动参与、自然融入群聊的“虚拟伙伴”。

## ✨ 核心功能

本插件包含两大核心功能，均可在后台独立开关。

### 1. 沉浸式对话 (Immersive Chat)

**痛点：** 每次和机器人连续对话都需要 `@` 它，打断了自然的聊天节奏。

**解决方案：** 当您和机器人聊天时，如果 LLM 认为可以进入更流畅的对话模式，它会调用一个特殊的函数工具。在此之后，**群聊中的下一条消息将被机器人视为直接对自己说的**，它会携带完整的上下文进行回复，全程无需 `@`！

**效果演示：**
> **你：** `/chat 帮我规划一下明天的学习计划，上午复习数学，下午学编程。`  
> **机器人：** (回复了学习计划...) 好的，计划已制定。如果你有其他想法，可以直接告诉我。 *(此时LLM在后台调用了`enable_direct_reply_once`函数)*  
> **你：** `下午的编程学习具体一点，我想学Python。` *(无需@机器人)*  
> **机器人：** (理解了上下文，直接回复) 好的，下午的Python学习可以分为...

此效果仅生效一次，确保了功能的精准可控，避免机器人过度响应。

### 2. 主动插话 (Proactive Interjection)

**痛点：** 机器人总是很被动，只有被 `@` 的时候才说话，无法参与到群友的日常讨论中。

**解决方案：** 当机器人在群聊中发言后，它会像一个真正的群友一样，“竖起耳朵”聆听大家的后续讨论。在一段可配置的延迟时间（如8秒）后，它会将这段时间的聊天记录打包，并询问 LLM：“根据刚才的讨论，我应该插句话吗？”

如果 LLM 认为时机合适（例如大家在讨论它擅长的话题），它就会生成一段回复，并主动发送到群里。这个过程是**持续循环**的，让机器人随时准备加入讨论。

**效果演示：**
> **机器人：** (回答了某个群友关于天气的问题) ...今天天气晴朗。  
> *(插件启动8秒倒计时...)*  
> **群友A：** `天气这么好，下午去打球怎么样？`  
> **群友B：** `好啊，去哪个球场？`  
> *(...8秒倒计时结束)*  
> **机器人：** (LLM判断可以插话，主动发送) `我知道附近有一个新开的篮球场，设施很棒，需要我提供具体位置吗？`

如果机器人在倒计时期间再次发言，计时器会自动重置，确保总是在机器人“说完话”之后开始聆听。

## 🚀 安装指南

1.  **克隆或下载仓库**
    ```bash
    git clone https://github.com/qa296/astrbot_plugin_reply_directly.git
    ```
    或者直接下载 ZIP 压缩包并解压。

2.  **放置插件**
    将解压后的 `astrbot_plugin_reply_directly` 文件夹完整地移动到您的 AstrBot 项目的 `data/plugins/` 目录下。

    目录结构应如下所示：
    ```
    AstrBot/
    └── data/
        └── plugins/
            └── astrbot_plugin_reply_directly/
                ├── main.py
                └── _conf_schema.json
    ```

3.  **重启 AstrBot**
    重启您的 AstrBot 程序，插件将会被自动加载。

## ⚙️ 配置说明

您可以在 AstrBot 的 **WebUI > 插件管理** 中找到本插件，并点击 **管理** 进入可视化配置界面。

| 配置项                  | 类型    | 默认值 | 描述                                                                                              |
| ----------------------- | ------- | ------ | ------------------------------------------------------------------------------------------------- |
| `插件总开关`            | `bool`  | `true` | 关闭后，本插件的所有功能都将失效。                                                                |
| `启用沉浸式对话功能`    | `bool`  | `true` | 是否允许机器人通过LLM的函数调用，实现对下一条消息的免@直接回复。                                  |
| `启用主动插话功能`      | `bool`  | `true` | 是否允许机器人在发言后，根据后续的聊天内容判断是否主动插话。                                      |
| `主动插话延迟时间（秒）`  | `int`   | `8`    | 机器人发言后，等待多少秒再收集聊天记录进行判断。建议设置为 `5` 到 `15` 秒之间，以获得最佳体验。 |

## 💡 使用技巧与最佳实践

*   **如何触发“沉浸式对话”？**
    此功能由 LLM 自主决定触发。您可以尝试通过 Prompt 引导它，例如：
    *   `“我们来连续聊几句，接下来你直接回答我，不用等我@你。”`
    *   `“关于这个话题，我们深入讨论一下。”`
    一个优秀的 LLM 能够理解您的意图，并在合适的时机调用工具来优化对话体验。

*   **“主动插话”的效果好坏取决于什么？**
    此功能的效果**高度依赖于您所使用的大语言模型（LLM）的判断能力**。一个强大的 LLM 能够更准确地判断何时应该插话，以及说什么样的话最合适。如果发现机器人插话过于频繁或不合时宜，可以适当调整您的 LLM 系统提示词（System Prompt）或更换模型。
